---
title: "Bayesian regression in Movies"
author: "Pimenta, V.A.P"
runtime: shiny
output: statsr:::statswithr_lab
---

## Setup

### Load packages

```{r load-packages, message = FALSE}
library(ggplot2)
library(dplyr)
library(statsr)
library(BAS)
library(ggpubr)
```

### Load data

Let's here load the data. We'll be calling it `movies`

```{r load-data}
load("/cloud/project/movies.Rdata")
```


* * *

## Part 1: Data

 The data is comprised of 651 randomly sampled movies produced and released before 2016. Information on the movies were gathered from Rotten Tomatoes and IMDB APIs.
 
 For the simple random sampling it's possible to generalize results for the population of movies from before 2016 and that are well represented in the data bank.
 
 It's quite clear that this is a observation study and *no causality* can be inferred from the study.


```{r}
movies <- na.omit(movies)
```

* * *

## Part 2: Data manipulation

  We'll be now creating and mutating the data set to have variables that are interesting for our purpose. 
  
  1) Creating a new variable based on `title_type` called `feature_film` with two levels: yes for a Feature film and no for another type of movie;

```{r}
movies <- movies %>%
  mutate(feature_film = ifelse(title_type == 'Feature Film', 'yes', 'no'))
```

  2) Creating a new variable based on `genre` called `drama` with levels yes (movies that are dramas) and no;

```{r}
movies <- movies %>%
  mutate(drama = ifelse(genre == 'Drama', 'yes', 'no'))
```

3) Creating a new variable based on `mpaa_rating` called `mpaa_rating_R` with levels yes (movies that are R rated) and no

```{r}
movies <- movies %>%
  mutate(mpaa_rating_R = ifelse(mpaa_rating == 'R', 'yes', 'no'))
```


4) Creating two new variables based on `thtr_rel_month`;

  A new variable called `oscar_season` with levels yes (if movie is released in November, October, or December) and no otherwise
    
```{r}
movies <- movies %>%
  mutate(oscar_season = ifelse(thtr_rel_month == '10', 'yes', 'no'),
         oscar_season = ifelse(thtr_rel_month == '11' , 'yes', 'no'),
         oscar_season = ifelse(thtr_rel_month == '12', 'yes', 'no'))
```    
    
  A new variable called `summer_season` with levels yes (if movie is released in May, June, July, or August) and no otherwise
    
```{r}
movies <- movies %>%
  mutate(summer_season = ifelse(thtr_rel_month == '4', 'yes', 'no'),
         summer_season = ifelse(thtr_rel_month == '5', 'yes', 'no'),
         summer_season = ifelse(thtr_rel_month == '6', 'yes', 'no'))
```

* * *

## Part 3: Exploratory data analysis

Lets start with a summary statistic on our variables;

```{r}
movies %>%
  group_by(feature_film) %>%
  summarise(count = n())

movies %>%
  group_by(drama) %>%
  summarise(count = n())

movies %>%
  group_by(mpaa_rating_R) %>%
  summarise(count = n())

movies %>%
  group_by(oscar_season) %>%
  summarise(count = n())

movies %>%
  group_by(summer_season) %>%
  summarise(count = n())
  
```

We have in all categories enough observations to infer what is needed and we have no NA's. We may proceed.


Let's now explore relations, in a boxplot, between our explanatory variables created and our response variable `audience_score`

```{r}
# for Feature Film
a <- ggplot(data = movies, aes(x = feature_film, y = audience_score)) +
  geom_boxplot()

# for Dramas
b <- ggplot(data = movies, aes(x = drama, y = audience_score)) +
  geom_boxplot()

# for mpaa_rating_R
c <- ggplot(data = movies, aes(x = mpaa_rating_R, y = audience_score)) +
  geom_boxplot()

# for oscar_season
d <- ggplot(data = movies, aes(x = oscar_season , y = audience_score)) +
  geom_boxplot()

# for summer_season
e <- ggplot(data = movies, aes(x = summer_season, y = audience_score)) +
  geom_boxplot()

ggarrange(a, b, c, d, e, 
          ncol = 2, nrow = 3)
```

  There is a visible difference between observations in a featured film and a not featured film. That's a good relation to explore. In other plots relations are not that obvious but there's still some difference worth exploring.
  

* * *

## Part 4: Modeling

We may now construct a bayesian model. That's the full version of the model.

```{r bas-wage}

model_bay_mov <- lm(data = movies, formula = audience_score ~ feature_film + drama + runtime + mpaa_rating_R + thtr_rel_year + oscar_season + summer_season + imdb_rating + imdb_num_votes + critics_score + best_pic_nom + best_pic_win + best_actor_win + best_actress_win + best_dir_win + top200_box)

summary(model_bay_mov)
```

Now let's begin to clear variables and modulate models.

We'll consider a uniform modelprior and use BIC for selection.

```{r}
# Fit the model using Bayesian linear regression, `bas.lm` function in the `BAS` package
bas_bay_mov <- bas.lm(audience_score ~ feature_film + drama + runtime + mpaa_rating_R + thtr_rel_year + oscar_season + summer_season + imdb_rating + imdb_num_votes + critics_score + best_pic_nom + best_pic_win + best_actor_win + best_actress_win + best_dir_win + top200_box, data = movies,
                   prior = "BIC", 
                   modelprior = uniform())

# Print out the marginal posterior inclusion probabilities for each variable                
bas_bay_mov

# Top 5 most probably models
summary(bas_bay_mov)

image(bas_bay_mov, rotate = F)
```

  With this printing we have a lot of information to process. Printing the model object gives us the posterior model inclusion probability for each variable. For example, the posterior probability that `runtime` is included in the model is 0.48077.

  We also have a lot of information on the top 5 most likely models. The most likely model, which has posterior probability of 0.1383, includes an intercept, runtime, imdb_rating and critics_score. It's posterior it's actually quite large but very similar to the second most likely model, wich doesn't include runtime.


We can also provide 95% credible intervals for the coefficients:

```{r vis-BMA}
coef(bas_bay_mov) %>%
  confint()
```

We're now ready to move on to predictions

* * *

## Part 5: Prediction


We'll be using *Highest Probability Model* (`HPM`)

```{r MPM}
HPM_pred_movies <- predict(bas_bay_mov, estimator = "HPM")
variable.names(HPM_pred_movies)
```

We'll use the movie `Donnie Darko`

Creating the data frame (We only need the variables that are going to be used in the Highest Predictive Model):

```{r}
#Donnie darko Data Frame - Step 1    
Donnie.darko <- data.frame(113, 8, 87, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA)      
  
#Naming the Data Frame - Step 2  
names(Donnie.darko) <- c("runtime", "imdb_rating", "critics_score", "feature_film" , "drama", "mpaa_rating_R", "thtr_rel_year", "oscar_season", "summer_season", "imdb_num_votes","best_pic_nom","best_pic_win" , "best_actor_win", "best_actress_win" , "best_dir_win" , "top200_box")  
```


Now that we have righfully added `Donnie Darko` to a dataframe. Lets do some predicting.


```{r warning=FALSE}
HPM_pred_darko <- predict(bas_bay_mov, newdata = Donnie.darko, estimator = "HPM", se.fit = TRUE)

ci_hpm_darko <- confint(HPM_pred_darko, estimator = "HPM")

ci_hpm_darko[1,]
```
Our real Audience Score is `80` and our prediction it's not far off. Altough there is probably better models to perform this regression as the interval goes beyond 100, what souldn't be permitted.


* * *

## Part 6: Conclusion

 To conclude, we were able to us variables avaible and it's transformations to create an good predictive bayesian model. There are some models with relevant posteriors. 
 
 Those are models that include `Intercept`, `runtime`, `imdb_rating`, `critics_score` and `Intercept`,`imdb_rating`,`critics_score`. The first was used with the HPM to predict the Audience Score for the movie Donnie Darko. Wich it was capable to do with merits.
 
 It would be great to model the regression to don't include values outside 0 < value < 100. That would be ideal for a next research.
