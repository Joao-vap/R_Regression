---
title: "LAB"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setting up

```{r}
library(ISLR)
names(Smarket)
```
```{r}
dim(Smarket)
summary(Smarket)
str(Smarket)
```
```{r}
pairs(Smarket)
cor(Smarket[,-9])
```
```{r}
attach(Smarket)
plot(Volume)
```


## RegressÃ£o Logistica


```{r}
glm.fits = glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial )
summary(glm.fits)
coef(glm.fits)
```

```{r}
summary (glm.fits)$coef
```

```{r}
glm.probs = predict (glm.fits, type = "response")
glm.probs[1:10]
```

```{r}
glm.pred=rep("Down", 1250)
glm.pred[glm.probs >.5] = "Up"
table(glm.pred, Direction)
mean(glm.pred==Direction )
```
There is some erros in this rate as we're applying the regression in the training data.

Diving the data in two for performing both:

```{r}
train = (Year < 2005)
Smarket.2005 = Smarket[!train,]
dim(Smarket.2005)
Direction.2005 = Direction[!train]
```

```{r}
glm.fits=glm(Direction~Lag1+Lag2+Lag3+Lag4+Lag5+Volume, data=Smarket, family=binomial, subset=train)
```

```{r}
glm.probs = predict(glm.fits, Smarket.2005, type="response")
```

```{r}
glm.pred=rep("Down",252)
glm.pred[glm.probs >.5]=" Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
```

Removing some predictors:

```{r}
glm.fits = glm(Direction ~ Lag1 + Lag2, data = Smarket, family = binomial, subset = train)
glm.probs = predict (glm.fits, Smarket.2005, type = "response")
glm.pred = rep("Down", 252)
glm.pred[glm.probs > .5] = "Up"
table(glm.pred, Direction.2005)
mean(glm.pred == Direction.2005)
```
```{r}
predict(glm.fits, newdata = data.frame(Lag1=c(1.2 ,1.5),Lag2=c(1.1,-0.8)), type = "response")
```

## LDA

```{r}
library(MASS)
lda.fit = lda(Direction~Lag1+Lag2 ,data=Smarket ,subset=train)
lda.fit
```
```{r}
lda.pred=predict (lda.fit , Smarket.2005)
lda.class=lda.pred$class
table(lda.class , Direction.2005)
```

```{r}
lda.pred$posterior [1:20,1]
lda.class [1:20]
```
## QDA

```{r}
qda.fit = qda(Direction ~ Lag1 + Lag2 ,data = Smarket ,subset = train)
qda.fit
```
```{r}
qda.class = predict(qda.fit ,Smarket.2005)$class
table(qda.class, Direction.2005)
```

## KNN

```{r}
library(class)
```

```{r}
train.X = cbind(Lag1 ,Lag2)[train,]
test.X = cbind(Lag1 ,Lag2)[!train,]
train.Direction = Direction[train]
```

```{r}
set.seed(1)
knn.pred = knn(train.X, test.X, train.Direction, k=1)
table(knn.pred ,Direction.2005)
```

```{r}
knn.pred=knn(train.X,test.X,train.Direction ,k=3)
table(knn.pred ,Direction.2005)
mean(knn.pred==Direction.2005)
```

# An Application to Caravan Insurance Data

```{r}
dim(Caravan)
```
```{r}
attach(Caravan)
summary(Purchase)
```
```{r}
standardized.X = scale(Caravan[,-86])
test <- 1:1000
train.X <- standardized.X[-test,]
test.X <- standardized.X[test,]
train.Y <- Purchase[-test]
test.Y <- Purchase[test]
set.seed(1)
knn.pred = knn(train.X, test.X, train.Y, k=1)
mean(test.Y != knn.pred)
```
```{r}
table(knn.pred ,test.Y)
```
```{r}
knn.pred=knn(train.X,test.X,train.Y,k=3)
table(knn.pred ,test.Y)

print('--------------')

knn.pred=knn(train.X,test.X,train.Y,k=5)
table(knn.pred ,test.Y)
```

Using a logistic curve.

```{r warning=FALSE}
glm.fits = glm(Purchase ~ ., data=Caravan, family=binomial, subset = -test) 
glm.probs = predict(glm.fits, Caravan[test,], type= "response")

##for 0.5 cutoff
glm.pred=rep("No", 1000)
glm.pred[glm.probs > .5]= "Yes"
table(glm.pred, test.Y)

##for 0.25 cutoff
glm.pred=rep("No", 1000)
glm.pred[glm.probs > .25] = "Yes"
table(glm.pred, test.Y)
```